[
  {
    "objectID": "syllabus/syllabus-overview.html",
    "href": "syllabus/syllabus-overview.html",
    "title": "Course overview",
    "section": "",
    "text": "What the course catalog says: Students apply statistical analysis skills to in-depth data analysis projects ranging across diverse application areas including but not limited to energy, environmental sustainability, global health, information and culture, brain sciences, and social networks. Students practice cutting-edge statistical methods and communicate their results both technically and non-technically via presentations and written reports.\nWhat JZ says: In a few months you will enter the working world as a professional with a degree in statistics. When you’re out there, a few things may happen:\n\nyou will be thrown onto a team with people you didn’t choose;\nyou will be told to use software you haven’t necessarily used;\nyou will be asked to study data from an unfamiliar domain;\nyou will be required to use new statistical methods you haven’t previously studied;\nyou will have to communicate your work to managers and stakeholders that know nothing about statistics.\n\nAre you ready for all that? To prepare you for the realities of modern data science practice, this class is essentially a sequence of group projects (case studies) where we confront you with messy, real world data analysis problems and coach you through how to tackle them using the statistical methods and the productivity tools (Quarto, R, Git, etc) that you studied in previous classes. Along the way, the instructors will introduce new statistical topics that you may find useful.\nPrerequisites: STA 360 or 402 (i.e. Bayes)."
  },
  {
    "objectID": "syllabus/syllabus-overview.html#description",
    "href": "syllabus/syllabus-overview.html#description",
    "title": "Course overview",
    "section": "",
    "text": "What the course catalog says: Students apply statistical analysis skills to in-depth data analysis projects ranging across diverse application areas including but not limited to energy, environmental sustainability, global health, information and culture, brain sciences, and social networks. Students practice cutting-edge statistical methods and communicate their results both technically and non-technically via presentations and written reports.\nWhat JZ says: In a few months you will enter the working world as a professional with a degree in statistics. When you’re out there, a few things may happen:\n\nyou will be thrown onto a team with people you didn’t choose;\nyou will be told to use software you haven’t necessarily used;\nyou will be asked to study data from an unfamiliar domain;\nyou will be required to use new statistical methods you haven’t previously studied;\nyou will have to communicate your work to managers and stakeholders that know nothing about statistics.\n\nAre you ready for all that? To prepare you for the realities of modern data science practice, this class is essentially a sequence of group projects (case studies) where we confront you with messy, real world data analysis problems and coach you through how to tackle them using the statistical methods and the productivity tools (Quarto, R, Git, etc) that you studied in previous classes. Along the way, the instructors will introduce new statistical topics that you may find useful.\nPrerequisites: STA 360 or 402 (i.e. Bayes)."
  },
  {
    "objectID": "syllabus/syllabus-overview.html#meetings",
    "href": "syllabus/syllabus-overview.html#meetings",
    "title": "Course overview",
    "section": "Meetings",
    "text": "Meetings\n\n\n\n\n\n\n\n\n\nMeeting\nLocation\nTime\nStaff\n\n\n\n\nLecture 001\nPerkins LINK 071 (Classroom 5)\nTuTh 8:30 AM - 9:45 AM\nJohn\n\n\nLecture 002\nPerkins LINK 071 (Classroom 5)\nMoWe 10:05 AM - 11:20 AM\nEd\n\n\nLab 01\nOld Chemistry 001\nF 1:25 PM - 2:40 PM\nAidan\n\n\nLab 02\nPerkins LINK 071 (Classroom 5)\nF 10:05 AM - 11:20 AM\nLuigi\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou must attend the lecture and lab section that you are enrolled in. Class activities will often be completed with your project groups, and project groups will be randomly assigned within sections."
  },
  {
    "objectID": "syllabus/syllabus-overview.html#team",
    "href": "syllabus/syllabus-overview.html#team",
    "title": "Course overview",
    "section": "Team",
    "text": "Team\n\n\n\n\n\n\n\n\n\nMug\nName\nRole\nOffice Hours\n\n\n\n\n\nIversen, Ed\nInstructor\nTh 4:00 PM - 5:00 PM\nOld Chemistry 122B\n\n\n\nZito, John\nInstructor\nTBD\nOld Chemistry 207\n\n\n\nKnox, Mary\nCourse Coordinator\nnone\n\n\n\nFan, Li\nTA\nM 7:00 PM - 9:00 PM\nZoom (link on Canvas)\n\n\n\nGleich, Aidan\nLab TA\nnone\n\n\n\nLi, Aihua\nTA\nW 2:30 PM - 4:30 PM\nOld Chem 203B\n\n\n\nMalgieri, Luigi\nLab TA\nnone\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe four TAs work with both sections, so feel free to seek help from any of them."
  },
  {
    "objectID": "syllabus/syllabus-resources.html",
    "href": "syllabus/syllabus-resources.html",
    "title": "University resources",
    "section": "",
    "text": "If you are having difficulty with the costs associated with this course (obtaining a laptop, mostly), here are some resources:\n\nKarsh Office of Undergraduate Support: Regardless of your aid package, Karsh offers loans and resources for connecting students with campus programs that might help alleviate course costs.\nDukeLIFE: The Course Material Assistance program offers assistance for eligible students, including through the LIFE Loaner Laptop Program. Students who are eligible for DukeLIFE benefits are notified before the start of the semester; program resources are limited.\nDuke Link: They have a small supply of laptops that can be rented out for five days at a time."
  },
  {
    "objectID": "syllabus/syllabus-resources.html#course-costs",
    "href": "syllabus/syllabus-resources.html#course-costs",
    "title": "University resources",
    "section": "",
    "text": "If you are having difficulty with the costs associated with this course (obtaining a laptop, mostly), here are some resources:\n\nKarsh Office of Undergraduate Support: Regardless of your aid package, Karsh offers loans and resources for connecting students with campus programs that might help alleviate course costs.\nDukeLIFE: The Course Material Assistance program offers assistance for eligible students, including through the LIFE Loaner Laptop Program. Students who are eligible for DukeLIFE benefits are notified before the start of the semester; program resources are limited.\nDuke Link: They have a small supply of laptops that can be rented out for five days at a time."
  },
  {
    "objectID": "syllabus/syllabus-resources.html#tech-support",
    "href": "syllabus/syllabus-resources.html#tech-support",
    "title": "University resources",
    "section": "Tech support",
    "text": "Tech support\nContact the Duke OIT Service Desk at oit.duke.edu/help."
  },
  {
    "objectID": "syllabus/syllabus-resources.html#writing-studio",
    "href": "syllabus/syllabus-resources.html#writing-studio",
    "title": "University resources",
    "section": "Writing Studio",
    "text": "Writing Studio\nPlease feel encouraged to set up a synchronous online appointment with the Writing Studio, a place beyond our classroom to work collaboratively with an attentive, nonevaluative reader. You can schedule an appointment at any stage in your writing process, including before you have even started writing. You’ll find friendly student consultants who are eager to talk with you about your writing and think with you about ways to make your processes even more effective. Visit https://twp.duke.edu/twp-writing-studio to schedule an appointment and to learn more about Writing Studio resources."
  },
  {
    "objectID": "syllabus/syllabus-resources.html#academic-support",
    "href": "syllabus/syllabus-resources.html#academic-support",
    "title": "University resources",
    "section": "Academic support",
    "text": "Academic support\nThere are times you may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (the ARC) offers services to support students academically during their undergraduate careers at Duke. The ARC can provide support with time management, academic skills and strategies, course-specific tutoring, and more. ARC services are available free to all Duke undergraduate student studying any discipline.\nYou can contact the Academic Resource Center by phone at (919) 684-5917, by email at theARC@duke.edu, or by visiting http://arc.duke.edu/."
  },
  {
    "objectID": "syllabus/syllabus-resources.html#accessibility",
    "href": "syllabus/syllabus-resources.html#accessibility",
    "title": "University resources",
    "section": "Accessibility",
    "text": "Accessibility\nIf any portion of the course is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students can engage with their courses and related assignments. Students should contact the SDAO to request or update accommodations under these circumstances."
  },
  {
    "objectID": "syllabus/syllabus-resources.html#mental-health-and-well-being",
    "href": "syllabus/syllabus-resources.html#mental-health-and-well-being",
    "title": "University resources",
    "section": "Mental health and well-being",
    "text": "Mental health and well-being\nDuke is committed to holistic student wellbeing, which includes one’s mental, emotional, and physical health. The university offers resources to help students manage daily stress, to encourage intentional self-care, and to access just-in-time support. If you find you need support, your mental and/or emotional health concerns are impacting your day-to-day activities, your academic performance, or you need someone to talk to, the resources below are available to you:\n\nDukeReach: DukeReach provides comprehensive outreach services to support students in managing all aspects of wellbeing, including referrals and follow-up services for students who are experiencing significant challenges related to mental health, physical health, social adjustment, and/or a variety of other stressors. You can contact the DukeReach team at dukereach@duke.edu;\nCounseling and Psychological Services (CAPS): CAPS offers counseling services to Duke students including virtual appointments, and referrals in the community. You do not need an appointment for an initial assessment. You may walk in or call 919-660-1000 to get started. Hours: Monday-Friday 9:00am - 4:00pm. After hours counseling services are available at no additional cost to students, you can call: 919-660-1000 Option 2;\nTimelyCare: TimelyCare is an online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling;\nDuke Student Health: Student Health offers a wide range of healthcare services for all Duke students, many of which are covered by the student health fee. To make an appointment call (919) 681-9355. Hours: Monday - Friday, 8am - 4:30pm, Thursday 9am - 4:30pm. Closed from 12-12:30 each day."
  },
  {
    "objectID": "slides/case-study-2.html#a-few-us-macro-aggregates",
    "href": "slides/case-study-2.html#a-few-us-macro-aggregates",
    "title": "Case Study 2",
    "section": "A few US macro aggregates",
    "text": "A few US macro aggregates\n\n\n\n\n\n\n\n\nThere are tons more. Play around on FRED!"
  },
  {
    "objectID": "slides/case-study-2.html#where-do-these-data-come-from",
    "href": "slides/case-study-2.html#where-do-these-data-come-from",
    "title": "Case Study 2",
    "section": "Where do these data come from?",
    "text": "Where do these data come from?\nBureau of Labor Statistics (under the Labor Department)\n\n\nConsumer Price Index (CPI);\n\n\nUnemployment;\n\nLabor Productivity;\n\nBureau of Economic Analysis (under the Commerce Department)\n\n\nGross Domestic Product (GDP);\n\nPersonal Consumption Expenditures (PCE).\n\nThere are 13 principal statistical agencies in the US federal government."
  },
  {
    "objectID": "slides/case-study-2.html#who-cares",
    "href": "slides/case-study-2.html#who-cares",
    "title": "Case Study 2",
    "section": "Who cares?",
    "text": "Who cares?\n\nThese are some of the most talked about data in the world. They are constantly being studied by…\n\n\n\n\n\n\n\n\n\nAcademics\n“how does the macroeconomy…work?”\n\n\nPolicymakers\n“what effect did our actions have?”\n\n\nBusinesses\n“how do we plan for the future?”\n\n\nJournalists\neach new release is a major headline…\n\n\nInvestors\n…followed by a second headline about how the stock and bond markets reacted.\n\n\n\n\n\nDid I leave anybody out?"
  },
  {
    "objectID": "slides/case-study-2.html#oh-right.",
    "href": "slides/case-study-2.html#oh-right.",
    "title": "Case Study 2",
    "section": "Oh, right.",
    "text": "Oh, right."
  },
  {
    "objectID": "slides/case-study-2.html#what-happened",
    "href": "slides/case-study-2.html#what-happened",
    "title": "Case Study 2",
    "section": "What happened?",
    "text": "What happened?\n\nAt 8:30 AM ET on Friday August 1, 2025, the BLS issued its regular monthly report on the US employment situation;\n\nIt includes total nonfarm payroll employment:\n\na measure of the number of U.S. workers in the economy that excludes proprietors, private household employees, unpaid volunteers, farm employees, and the unincorporated self-employed. This measure accounts for approximately 80 percent of the workers who contribute to Gross Domestic Product (GDP). This measure provides useful insights into the current economic situation because it can represent the number of jobs added or lost in an economy.\n\n\nPresidents want to take credit for this going up each month."
  },
  {
    "objectID": "slides/case-study-2.html#what-happened-1",
    "href": "slides/case-study-2.html#what-happened-1",
    "title": "Case Study 2",
    "section": "What happened?",
    "text": "What happened?\nThe August 1 report announced the initial release of the July numbers, as well as revisions to the May and June numbers:\n\n\nSource: Madeleine Ngo in the New York Times, August 1 2025."
  },
  {
    "objectID": "slides/case-study-2.html#what-happened-2",
    "href": "slides/case-study-2.html#what-happened-2",
    "title": "Case Study 2",
    "section": "What happened?",
    "text": "What happened?\nThe Commissioner of Labor Statistics was fired that afternoon:\n\n\n\n\nSource: Truth Social.\n\n\n\n\nSource: Truth Social"
  },
  {
    "objectID": "slides/case-study-2.html#whence-revisions",
    "href": "slides/case-study-2.html#whence-revisions",
    "title": "Case Study 2",
    "section": "Whence revisions?",
    "text": "Whence revisions?\nThe statistical agencies announce an initial estimate with a one period lag, but they continue to revise the measurement (sometimes years later) as new information arrives and measurement techniques improve.\n\nFrom the BLS report (and more here):\n\nMonthly revisions result from additional reports received from businesses and government agencies since the last published estimates and from the recalculation of seasonal factors.\n\n\n\nFrom Ben Casselman at the New York Times:\n\nThe monthly numbers are based on a huge survey of businesses and other employers. Not all businesses respond in time for the initial estimate, however, forcing government statisticians to fill in the gaps with a statistical technique that essentially assumes the businesses that didn’t respond behaved the same way as the ones that did. That approach works fine during normal times. But during periods of rapid change, that assumption can be misleading."
  },
  {
    "objectID": "slides/case-study-2.html#frbps-real-time-data-set",
    "href": "slides/case-study-2.html#frbps-real-time-data-set",
    "title": "Case Study 2",
    "section": "FRBP’s Real-Time Data Set",
    "text": "FRBP’s Real-Time Data Set\n\n\n\n\n\nTracks the entire history of revisions for key macroeconomic variables.\n\nCheck it out!"
  },
  {
    "objectID": "slides/case-study-2.html#what-are-these-data-like",
    "href": "slides/case-study-2.html#what-are-these-data-like",
    "title": "Case Study 2",
    "section": "What are these data like?",
    "text": "What are these data like?\nQuarterly GDP growth (year-over-year percent change):\n\n\n# A tibble: 244 × 10\n   DATE    v65Q4 v66Q1 v66Q2 v66Q3 v66Q4 v67Q1 v67Q2 v67Q3 v67Q4\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 1965:Q1  5.36  5.40  5.40  5.37  5.37  5.37  5.37  5.32  5.32\n 2 1965:Q2  4.43  4.79  4.79  5.14  5.14  5.14  5.14  5.38  5.38\n 3 1965:Q3  4.55  5.22  5.22  5.68  5.68  5.68  5.68  5.96  5.96\n 4 1965:Q4 NA     6.33  6.79  7.49  7.49  7.49  7.49  7.80  7.80\n 5 1966:Q1 NA    NA     6.04  6.70  6.70  6.70  6.70  7.30  7.30\n 6 1966:Q2 NA    NA    NA     5.99  5.87  5.87  5.87  6.49  6.49\n 7 1966:Q3 NA    NA    NA    NA     5.26  5.13  5.13  5.49  5.49\n 8 1966:Q4 NA    NA    NA    NA    NA     4.09  4.12  4.21  4.21\n 9 1967:Q1 NA    NA    NA    NA    NA    NA     2.61  2.37  2.37\n10 1967:Q2 NA    NA    NA    NA    NA    NA    NA     2.36  2.37\n# ℹ 234 more rows\n\n\n\nA single variable gets a whole data frame with an upper triangular structure:\n\nrow = what period are measuring?\ncolumn = when were we measuring it?"
  },
  {
    "objectID": "slides/case-study-2.html#what-are-these-data-like-1",
    "href": "slides/case-study-2.html#what-are-these-data-like-1",
    "title": "Case Study 2",
    "section": "What are these data like?",
    "text": "What are these data like?\nQuarterly GDP growth (year-over-year percent change):\n\noutput_growth |&gt;\n  select(DATE, v66Q3) |&gt;\n  filter(DATE == \"1965:Q3\")\n\n# A tibble: 1 × 2\n  DATE    v66Q3\n  &lt;chr&gt;   &lt;dbl&gt;\n1 1965:Q3  5.68\n\n\nThis is our estimate of GDP growth in 1965:Q3 as measured a year later in 1966:Q3."
  },
  {
    "objectID": "slides/case-study-2.html#columns-are-vintages",
    "href": "slides/case-study-2.html#columns-are-vintages",
    "title": "Case Study 2",
    "section": "Columns are vintages\n",
    "text": "Columns are vintages\n\nQuarterly GDP growth (year-over-year percent change):\n\noutput_growth |&gt;\n  select(DATE, v66Q3)\n\n# A tibble: 304 × 2\n   DATE    v66Q3\n   &lt;chr&gt;   &lt;dbl&gt;\n 1 1950:Q1  4.65\n 2 1950:Q2  8.06\n 3 1950:Q3 11.3 \n 4 1950:Q4 14.5 \n 5 1951:Q1 10.4 \n 6 1951:Q2  9.47\n 7 1951:Q3  7.14\n 8 1951:Q4  5.03\n 9 1952:Q1  4.43\n10 1952:Q2  2.12\n# ℹ 294 more rows\n\n\nThis column is the 1966:Q3 vintage of the data. This is history as it was understood in 1966:Q3."
  },
  {
    "objectID": "slides/case-study-2.html#rows-are-the-history-of-revisions",
    "href": "slides/case-study-2.html#rows-are-the-history-of-revisions",
    "title": "Case Study 2",
    "section": "Rows are the history of revisions",
    "text": "Rows are the history of revisions\nQuarterly GDP growth (year-over-year percent change):\n\noutput_growth |&gt;\n  filter(DATE == \"1965:Q3\")\n\n\n\n# A tibble: 1 × 11\n  DATE    v65Q4 v66Q1 v66Q2 v66Q3 v66Q4 v67Q1 v67Q2 v67Q3 v67Q4 v68Q1\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1965:Q3  4.55  5.22  5.22  5.68  5.68  5.68  5.68  5.96  5.96  5.96\n\n\nHow did our measurement for 1965:Q3 evolve over time as it was revised?"
  },
  {
    "objectID": "slides/case-study-2.html#in-my-life",
    "href": "slides/case-study-2.html#in-my-life",
    "title": "Case Study 2",
    "section": "In My Life",
    "text": "In My Life\n\n\n\n\n\nMoving across the columns:"
  },
  {
    "objectID": "slides/case-study-2.html#the-path-of-revisions",
    "href": "slides/case-study-2.html#the-path-of-revisions",
    "title": "Case Study 2",
    "section": "The path of revisions",
    "text": "The path of revisions\nMoving across a fixed row:"
  },
  {
    "objectID": "slides/case-study-2.html#how-do-data-revisions-behave",
    "href": "slides/case-study-2.html#how-do-data-revisions-behave",
    "title": "Case Study 2",
    "section": "How do data revisions behave?",
    "text": "How do data revisions behave?\n\n\n\n\n\n\n\nGood heavens"
  },
  {
    "objectID": "slides/case-study-2.html#how-do-data-revisions-behave-1",
    "href": "slides/case-study-2.html#how-do-data-revisions-behave-1",
    "title": "Case Study 2",
    "section": "How do data revisions behave?",
    "text": "How do data revisions behave?\nAruoba (2008 JMCB):\n\nWe document the empirical properties of revisions to major macroeconomic variables in the United States. Our findings suggest that they do not satisfy simple desirable statistical properties. In particular, we find that these revisions do not have a zero mean, which indicates that the initial announcements by statistical agencies are biased. We also find that the revisions are quite large compared to the original variables and they are predictable using the information set at the time of the initial announcement, which means that the initial announcements of statistical agencies are not rational forecasts.\n\n\nBummer."
  },
  {
    "objectID": "slides/case-study-2.html#this-is-probably-getting-worse",
    "href": "slides/case-study-2.html#this-is-probably-getting-worse",
    "title": "Case Study 2",
    "section": "This is probably getting worse",
    "text": "This is probably getting worse\n\nFederal statistical agencies have faced mounting challenges in recent years as Americans have become more reluctant to respond to the surveys that are the basis for much of the nation’s economic data. Shrinking budgets have made it harder to make up for falling response rates, and to develop new approaches to replace surveys altogether.\n\nSource: New York Times."
  },
  {
    "objectID": "slides/case-study-2.html#picture-this",
    "href": "slides/case-study-2.html#picture-this",
    "title": "Case Study 2",
    "section": "Picture this",
    "text": "Picture this\nImagine you work at the Federal Reserve, or the Congressional Budget Office, or Goldman Sachs, or The Wall Street Journal. Your boss taps you on the shoulder and says:\n\nWe just got an unexpected data release, but we know it will be revised. And in general, I’m sick of this crap where the numbers swing around for months after the fact and we don’t know where we stand. Can you develop a model that can predict where the measurement will settle after the revisions are done?"
  },
  {
    "objectID": "slides/case-study-2.html#your-task",
    "href": "slides/case-study-2.html#your-task",
    "title": "Case Study 2",
    "section": "Your task",
    "text": "Your task\nData: the full set of historical vintages for several macro variables.\nEach team will be assigned a target variable. Then:\n\nDevelop a model that can predict the final release of the variable using only information available at the time of the initial release;\n\ntreat the vintage three years later as the final release;\nUse the other variables as predictors if you want;\nProduce a method with good historical performance averaged over time;\n\n\nYou must quantify uncertainty. Point predictions are not enough. You need to produce and evaluate full predictive distributions that incorporate as many sources of uncertainty as possible."
  },
  {
    "objectID": "slides/case-study-2.html#deadlines",
    "href": "slides/case-study-2.html#deadlines",
    "title": "Case Study 2",
    "section": "Deadlines",
    "text": "Deadlines\n\nEDA presentations (Wed 2/11):\n\nthe usual plots and summaries to get a feel and motivate your analysis;\nhit the books and teach the class how your assigned variable is actually measured, and what goes on during the revision process;\n\n\nAnalysis presentations (Wed 2/18):\n\nwhat models did you consider?\nhow did their predictive accuracy compare?\ncan you interpret why the models performed the way they did?\n\n\nFinal submission (Mon 2/23)."
  },
  {
    "objectID": "slides/case-study-2.html#lecture-topics",
    "href": "slides/case-study-2.html#lecture-topics",
    "title": "Case Study 2",
    "section": "Lecture topics",
    "text": "Lecture topics\nA crash course in time series:\n\nAutoregressive moving average (ARMA) models;\nDynamic linear models (DLMs);\nProbabilistic prediction;\nTime series cross-validation (“leave-future-out”).\n\nYou may not ultimately choose to use these specific models, but the evaluation techniques are model-agnostic."
  },
  {
    "objectID": "slides/case-study-2.html#words-of-caution",
    "href": "slides/case-study-2.html#words-of-caution",
    "title": "Case Study 2",
    "section": "Words of caution",
    "text": "Words of caution\n\nThe data come in this funky, unfamiliar form: each variable gets its own data frame with this triangular structure (row = period being measured; column = vintage). How are you going to deal with that?\nWhen you generate a prediction, make sure you are conditioning only on information that would have been available at that time!\nThere already exists a massive literature on this, which you are welcome to explore. However, you will quickly become overwhelmed if you’re not careful. That’s part of the challenge!\nBlack box machine learning methods may or may not work well here, but if you don’t know how to get predictive uncertainty quantification from them, or you find that the UQ is unreliable, then say goodbye to XGBoost!"
  },
  {
    "objectID": "slides/case-study-2.html#not-just-point-prediction",
    "href": "slides/case-study-2.html#not-just-point-prediction",
    "title": "Case Study 2",
    "section": "Not just point prediction",
    "text": "Not just point prediction"
  },
  {
    "objectID": "slides/case-study-2.html#point-prediction",
    "href": "slides/case-study-2.html#point-prediction",
    "title": "Case Study 2",
    "section": "Point prediction",
    "text": "Point prediction\nYour single-number best guess at tomorrow’s observation:"
  },
  {
    "objectID": "slides/case-study-2.html#prediction-interval",
    "href": "slides/case-study-2.html#prediction-interval",
    "title": "Case Study 2",
    "section": "Prediction interval",
    "text": "Prediction interval\nA range of likely values for tomorrow’s observation:"
  },
  {
    "objectID": "slides/case-study-2.html#prediction-distribution-density",
    "href": "slides/case-study-2.html#prediction-distribution-density",
    "title": "Case Study 2",
    "section": "Prediction distribution (density)",
    "text": "Prediction distribution (density)\nFull distribution capturing uncertainty about tomorrow:"
  },
  {
    "objectID": "slides/case-study-2.html#and-then-tomorrow-finally-comes",
    "href": "slides/case-study-2.html#and-then-tomorrow-finally-comes",
    "title": "Case Study 2",
    "section": "And then tomorrow finally comes",
    "text": "And then tomorrow finally comes\nSo…how’d we do? Any ideas?"
  },
  {
    "objectID": "slides/case-study-2.html#whats-the-point",
    "href": "slides/case-study-2.html#whats-the-point",
    "title": "Case Study 2",
    "section": "What’s the point?",
    "text": "What’s the point?\n\nWe want intervals and densities to communicate uncertainty about the prediction;\n\nWhat sources of uncertainty?\n\nData uncertainty (data are realization of random process);\nParameter estimation uncertainty;\nHyperparameter tuning uncertainty;\nModel uncertainty;\nUncertainty introduced by missing data;\nWhat else?\n\n\n\n\nNewsflash: you have seen this before."
  },
  {
    "objectID": "slides/case-study-2.html#regression-101-interval-estimation",
    "href": "slides/case-study-2.html#regression-101-interval-estimation",
    "title": "Case Study 2",
    "section": "Regression 101: interval estimation",
    "text": "Regression 101: interval estimation\nRemember this picture?"
  },
  {
    "objectID": "slides/case-study-2.html#regression-101",
    "href": "slides/case-study-2.html#regression-101",
    "title": "Case Study 2",
    "section": "Regression 101",
    "text": "Regression 101\nRecall the simple linear model:\n\\[\n\\begin{aligned}\ny_i&=\\mu(x_i)+\\varepsilon_i && \\varepsilon_i\\iid\\N(0\\com\\sigma^2)\\\\\n&=\\beta_0+\\beta_1x_i+\\varepsilon_i\\\\\n\\end{aligned}\n\\]\n\nThe OLS estimators are:\n\\[\n\\begin{aligned}\n\\hat{\\beta}_1\n&=\n\\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{S_{xx}},&&S_{xx}=\\sum\\limits_{i=1}^n(x_i-\\bar{x})^2\n\\\\\n\\hat{\\beta}_0\n&=\n\\bar{y}-\\bar{x}\\hat{\\beta}_1\n\\\\\n\\hat{\\mu}(x)\n&=\n\\hat{\\beta}_0+\\hat{\\beta_1}x\n\\\\\n\\widehat{\\sigma^2}\n&=\n\\frac{1}{n-2}\\sum\\limits_{i=1}^n[y_i-\\hat{\\mu}(x_i)]^2.\n\\end{aligned}\n\\]\n\n\nThe main idea of classical statistics is that the estimators are random variables as a function of the data. We quantify the uncertainty in the estimate that is induced by the sampling process."
  },
  {
    "objectID": "slides/case-study-2.html#sampling-distributions",
    "href": "slides/case-study-2.html#sampling-distributions",
    "title": "Case Study 2",
    "section": "Sampling distributions",
    "text": "Sampling distributions\nYou can show that the sampling distributions are independent, and\n\\[\n\\begin{aligned}\n\\begin{bmatrix}\n\\hat{\\beta}_0\n\\\\\n\\hat{\\beta}_1\n\\end{bmatrix}\n&\\sim\n\\text{N}_2\\left(\\begin{bmatrix}\\beta_0\\\\\\beta_1\\end{bmatrix}\n\\com\n\\sigma^2\n\\begin{bmatrix}\n\\frac{1}{n}+\\frac{\\bar{x}^2}{S_{xx}}&-\\bar{x}/S_{xx}\\\\-\\bar{x}/S_{xx}&1/S_{xx}\n\\end{bmatrix}\\right)\n\\\\\n\\widehat{\\sigma^2}\n&\\sim\n\\text{Gamma}\\left(\\frac{n-2}{2}\\com\\frac{n-2}{2\\sigma^2}\\right)\n.\n\\end{aligned}\n\\]\n\nThe estimator of the regression function is the sum of two correlated Gaussian terms, so it stays normal, you add the means, and you add the variances, adjusting for the covariance:\n\n\n\\[\n\\hat{\\mu}(x)=\\hat{\\beta}_0+\\hat{\\beta_1}x\\sim\\N\\left(\\beta_0+\\beta_1x\\com \\sigma^2\\left[\\frac{1}{n}+\\frac{(x-\\bar{x})^2}{S_{xx}}\\right]\\right)\n\\]\n\n\nTake my word for it!"
  },
  {
    "objectID": "slides/case-study-2.html#the-confidence-interval-for-the-line",
    "href": "slides/case-study-2.html#the-confidence-interval-for-the-line",
    "title": "Case Study 2",
    "section": "The confidence interval for the line",
    "text": "The confidence interval for the line\nA tale of two pivots:\n\n\\[\n\\frac{\\hat{\\mu}(x)-\\mu(x)}{\\sigma\\sqrt{\\frac{1}{n}+\\frac{(x-\\bar{x})^2}{S_{xx}}}}\n\\sim\\N(0\\com 1) \\quad\\implies\\quad \\frac{\\hat{\\mu}(x)-\\mu(x)}{\\hat{\\sigma}\\sqrt{\\frac{1}{n}+\\frac{(x-\\bar{x})^2}{S_{xx}}}}\n\\sim t_{n-2}.\n\\]\n\n\nSo we can use quantiles of the \\(t\\) distribution to get an exact interval for the unknow regression function at a new \\(x\\):\n\n\n\\[\n\\hat{\\mu}(x)\\pm t^\\star_{n-2}\\times \\hat{\\sigma}\\sqrt{\\frac{1}{n}+\\frac{(x-\\bar{x})^2}{S_{xx}}}.\n\\]\nThis quantifies frequentist sampling uncertainty for the regression line."
  },
  {
    "objectID": "slides/case-study-2.html#the-predictive-pivot",
    "href": "slides/case-study-2.html#the-predictive-pivot",
    "title": "Case Study 2",
    "section": "The predictive pivot",
    "text": "The predictive pivot\nIf a new \\(\\tilde{x}\\) joins the party, we have\n\n\n\\(\\tilde{y}\\sim\\text{N}(\\mu(\\tilde{x})\\com\\sigma^2)\\);\n\\(\\hat{\\mu}(x)\\sim\\N\\left(\\mu(\\tilde{x})\\com \\sigma^2\\left[\\frac{1}{n}+\\frac{(x-\\bar{x})^2}{S_{xx}}\\right]\\right)\\)\nThese are independent.\n\n\nTheir difference is normal, and you subtract the means and add the variance:\n\\[\n\\begin{aligned}\n\\hat{\\mu}(\\tilde{x})-\\tilde{y} &\\sim\\N\\left(0\\com \\sigma^2\\left[\\frac{1}{n}+\\frac{(\\tilde{x}-\\bar{x})^2}{S_{xx}}\\right]+\\sigma^2\\right)\n\\\\\n&\\sim\\N\\left(0\\com \\sigma^2\\left[1+\\frac{1}{n}+\\frac{(\\tilde{x}-\\bar{x})^2}{S_{xx}}\\right]\\right).\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/case-study-2.html#the-prediction-interval-for-a-new-observation",
    "href": "slides/case-study-2.html#the-prediction-interval-for-a-new-observation",
    "title": "Case Study 2",
    "section": "The prediction interval for a new observation",
    "text": "The prediction interval for a new observation\nA tale of two more pivots:\n\n\\[\n\\frac{\\hat{\\mu}(\\tilde{x})-\\tilde{y}}{\\sigma\\sqrt{1+\\frac{1}{n}+\\frac{(\\tilde{x}-\\bar{x})^2}{S_{xx}}}}\n\\sim\\N(0\\com 1) \\quad\\implies\\quad \\frac{\\hat{\\mu}(\\tilde{x})-\\tilde{y}}{\\hat{\\sigma}\\sqrt{1+\\frac{1}{n}+\\frac{(\\tilde{x}-\\bar{x})^2}{S_{xx}}}}\n\\sim t_{n-2}.\n\\]\n\n\nExact prediction interval for a yet-to-be-observed \\(\\tilde{y}\\):\n\n\n\\[\n\\hat{\\mu}(\\tilde{x})\\pm t^\\star_{n-2}\\times \\hat{\\sigma}\\sqrt{1+\\frac{1}{n}+\\frac{(\\tilde{x}-\\bar{x})^2}{S_{xx}}}.\n\\]\n\n\nThis is wider than the confidence interval because the inherent random sampling of the new \\(\\tilde{y}\\) (its \\(\\tilde{\\varepsilon}\\)) adds a second source of uncertainty."
  },
  {
    "objectID": "slides/case-study-2.html#you-get-the-idea",
    "href": "slides/case-study-2.html#you-get-the-idea",
    "title": "Case Study 2",
    "section": "You get the idea",
    "text": "You get the idea\nThe CI incorporates one source of uncertainty. The PI incorporates two. Hence, the PI is wider:\n\nmtcars_fit &lt;- lm(mpg ~ wt, data = mtcars)\nxnew &lt;- data.frame(wt = 4.5)\n\npredict(mtcars_fit, xnew, interval = \"confidence\")\n\n     fit      lwr      upr\n1 13.235 11.40347 15.06654\n\npredict(mtcars_fit, xnew, interval = \"prediction\")\n\n     fit      lwr      upr\n1 13.235 6.750452 19.71956"
  },
  {
    "objectID": "slides/case-study-2.html#bayes-101-posterior-predictive-distribution",
    "href": "slides/case-study-2.html#bayes-101-posterior-predictive-distribution",
    "title": "Case Study 2",
    "section": "Bayes 101: posterior predictive distribution",
    "text": "Bayes 101: posterior predictive distribution\nThe posterior for parameters:\n\\[\np(\\boldsymbol{\\theta}\\mid y_{1:n})\n=\n\\frac{p(y_{1:n}\\mid \\boldsymbol{\\theta})p(\\boldsymbol{\\theta})}{p(y_{1:n})}.\n\\]\n\nThe posterior for a new observation:\n\\[\np(\\tilde{y}\\mid y_{1:n})=\\int p(\\tilde{y}\\mid \\boldsymbol{\\theta})p(\\boldsymbol{\\theta}\\mid y_{1:n})\\,\\text{d}\\boldsymbol{\\theta}\n.\n\\]\n\n\nSimilar to before, it incorporates Bayesian posterior uncertainty about the parameter and inherent randomness of new \\(\\tilde{y}\\)."
  },
  {
    "objectID": "slides/case-study-2.html#example-linear-regression-again",
    "href": "slides/case-study-2.html#example-linear-regression-again",
    "title": "Case Study 2",
    "section": "Example: linear regression, again",
    "text": "Example: linear regression, again\nConsider linear regression where the prior \\(p(\\sigma^2\\com\\Bbeta)\\) is conjugate:\n\n\\[\n\\begin{aligned}\n\\sigma^2\n&\\sim\n\\text{IG}(a_0\\com b_0)\n\\\\\n\\Bbeta\\mid \\sigma^2\n&\\sim\n\\text{N}_{p}(\\bar{\\Bbeta}_0\\com\\sigma^2\\BH^{-1}_0)\n\\\\\ny_i\n\\mid\n\\Bx_i\n\\com\n\\Bbeta\\com\\sigma^2\n&\\iid \\text{N}\n\\left(\n\\Bx_i^\\tr\\Bbeta\\com\\sigma^2\n\\right).\n\\end{aligned}\n\\]\n\n\nWithout revisiting the pain and tedium of the calculation, the posterior \\(p(\\sigma^2\\com\\Bbeta\\mid y_{1:n}\\com \\Bx_{1:n})\\) remains in the normal-inverse-gamma family with updated hyperparameters:\n\\[\n\\begin{aligned}\n\\sigma^2\\mid y_{1:n}\\com \\Bx_{1:n}\n&\\sim\n\\text{IG}(a_n\\com b_n)\n\\\\\n\\Bbeta\\mid \\sigma^2\\com y_{1:n}\\com \\Bx_{1:n}\n&\\sim\n\\text{N}_{p}(\\bar{\\Bbeta}_n\\com\\sigma^2\\BH^{-1}_n)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/case-study-2.html#example-linear-regression-again-1",
    "href": "slides/case-study-2.html#example-linear-regression-again-1",
    "title": "Case Study 2",
    "section": "Example: linear regression, again",
    "text": "Example: linear regression, again\nImagine we’ve observed the \\((\\Bx_i\\com y_i)\\), and then a new \\(\\tilde{\\Bx}\\) joins the party:\n\n\\[\n\\begin{aligned}\n\\sigma^2\\mid y_{1:n}\\com \\Bx_{1:n}\n&\\sim\n\\text{IG}(a_n\\com b_n)\n\\\\\n\\Bbeta\\mid \\sigma^2\\com y_{1:n}\\com \\Bx_{1:n}\n&\\sim\n\\text{N}_{p}(\\bar{\\Bbeta}_n\\com\\sigma^2\\BH^{-1}_n)\n\\\\\n\\\\\n\\tilde{y}&=\\tilde{\\Bx}^\\tr\\Bbeta+\\tilde{\\varepsilon},\\quad \\tilde{\\varepsilon}\\sim\\text{N}(0\\com\\sigma^2).\n\\end{aligned}\n\\]\n\n\nThe posterior predictive distribution is the marginal:\n\n\n\\[\n\\begin{aligned}\np(\\tilde{y}\\mid \\tilde{\\Bx}\\com y_{1:n}\\com \\Bx_{1:n})\n&=\n\\int\\int\np(\\tilde{y}\\com\\sigma^2\\com\\Bbeta\\mid \\tilde{\\Bx}\\com y_{1:n}\\com \\Bx_{1:n})\n\\,\\dd\\Bbeta\\,\\dd\\sigma^2\n\\\\\n&=\n\\int\\int\n\\underbrace{p(\\tilde{y}\\mid \\tilde{\\Bx}\\com \\sigma^2\\com\\Bbeta)}_{\\N(\\tilde{\\Bx}^\\tr\\Bbeta\\com\\sigma^2)}\n\\underbrace{p(\\sigma^2\\com\\Bbeta\\mid y_{1:n}\\com \\Bx_{1:n})}_{\\text{NIG}_{p}(a_n\\com b_n\\com \\bar{\\Bbeta}_n\\com\\BH_n)}\n\\,\\dd\\Bbeta\\,\\dd\\sigma^2.\n\\end{aligned}\n\\]\n\n\nWe can actually solve this."
  },
  {
    "objectID": "slides/case-study-2.html#first-marginalize-out-bbeta",
    "href": "slides/case-study-2.html#first-marginalize-out-bbeta",
    "title": "Case Study 2",
    "section": "First: marginalize out \\(\\Bbeta\\)\n",
    "text": "First: marginalize out \\(\\Bbeta\\)\n\nWe know that\n\\[\n\\begin{aligned}\n\\Bbeta\\mid \\sigma^2\\com y_{1:n}\\com \\Bx_{1:n}\n&\\sim\n\\text{N}_{p}(\\bar{\\Bbeta}_n\\com\\sigma^2\\BH^{-1}_n)\n\\\\\n\\tilde{y}\n&=\n\\tilde{\\Bx}^\\tr\\Bbeta\n+\n\\tilde{\\varepsilon}\n,\n&&\n\\tilde{\\varepsilon}\\sim\\N(0\\com \\sigma^2).\n\\end{aligned}\n\\]\n\nPre-multiplying by \\(\\tilde{\\Bx}^\\tr\\) is just a linear transformation, so:\n\\[\n\\tilde{\\Bx}^\\tr\\Bbeta\n\\mid \\tilde{\\Bx}\\com \\sigma^2\\com y_{1:n}\\com \\Bx_{1:n}\n\\sim\n\\N(\n\\tilde{\\Bx}^\\tr\\bar{\\Bbeta}_n\n\\com\n\\sigma^2\\tilde{\\Bx}^\\tr\\BH_n^{-1}\\tilde{\\Bx}\n).\n\\]\n\n\nSince \\(\\tilde{y}\\) is the sum of two independent normal bits (\\(\\tilde{\\Bx}^\\tr\\Bbeta\\) and \\(\\tilde{\\varepsilon}\\)), it stays normal, and you can add the means and variance:\n\n\n\\[\n\\begin{aligned}\n\\tilde{y}\\mid \\tilde{\\Bx}\\com \\sigma^2\\com y_{1:n}\\com \\Bx_{1:n}\n&\\sim\n\\N\\left(\n\\tilde{\\Bx}^\\tr\\bar{\\Bbeta}_n+0\n\\com\n\\sigma^2\\tilde{\\Bx}^\\tr\\BH_n^{-1}\\tilde{\\Bx}+\\sigma^2\n\\right)\n\\\\\n&\\sim\n\\N\\left(\n\\tilde{\\Bx}^\\tr\\bar{\\Bbeta}_n\n\\com\n\\sigma^2(1+\\tilde{\\Bx}^\\tr\\BH_n^{-1}\\tilde{\\Bx})\n\\right).\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/case-study-2.html#second-marginalize-out-sigma2",
    "href": "slides/case-study-2.html#second-marginalize-out-sigma2",
    "title": "Case Study 2",
    "section": "Second: marginalize out \\(\\sigma^2\\)\n",
    "text": "Second: marginalize out \\(\\sigma^2\\)\n\nWe know that\n\\[\n\\begin{aligned}\n\\sigma^2\\mid y_{1:n}\\com \\Bx_{1:n}\n&\\sim\n\\text{IG}(a_n\\com b_n)\n\\\\\n\\tilde{y}\\mid \\tilde{\\Bx}\\com \\sigma^2\\com y_{1:n}\\com \\Bx_{1:n}\n&\\sim\n\\N\\left(\n\\tilde{\\Bx}^\\tr\\bar{\\Bbeta}_n\n\\com\n\\sigma^2(1+\\tilde{\\Bx}^\\tr\\BH_n^{-1}\\tilde{\\Bx})\n\\right).\n\\end{aligned}\n\\]\n\nMarginalizing \\(\\sigma^2\\) out of this hierarchy is essentially the definition of Student’s \\(t\\):\n\n\n\\[\n\\begin{aligned}\n\\tilde{y}\\mid \\tilde{\\Bx}\\com y_{1:n}\\com \\Bx_{1:n}\n&\\sim\nt(\\nu_n\\com\\bar{y}_{n}\\com s_{n}^2)\n\\\\\n\\\\\n\\nu_{n}\n&=\n2a_n\n\\\\\n\\bar{y}_{n}\n&=\n\\tilde{\\Bx}^\\tr\\bar{\\Bbeta}_n\n\\\\\ns_{n}^2\n&=\n\\frac{b_n}{a_n}\n(1+\\tilde{\\Bx}^\\tr\\BH_n^{-1}\\tilde{\\Bx})\n.\n\\end{aligned}\n\\]\n\n\nSo, Student’s \\(t\\) with a shift and scale."
  },
  {
    "objectID": "slides/case-study-2.html#comparison",
    "href": "slides/case-study-2.html#comparison",
    "title": "Case Study 2",
    "section": "Comparison",
    "text": "Comparison\n\n\nClassical prediction interval:\n\\[\n\\begin{aligned}\n\\hat{y} &\\pm t^\\star_{n-2} \\times \\text{SE}\n\\\\\n\\\\\n\\hat{y}\n&=\n\\hat{\\beta_0}+\\hat{\\beta}_1\\tilde{x}\n\\\\\n\\text{SE}^2\n&=\n\\widehat{\\sigma^2}\\left(1+\\frac{1}{n}+\\frac{(\\tilde{x}-\\bar{x})^2}{S_{xx}}\\right).\n\\end{aligned}\n\\]\n\nPosterior predictive distribution:\n\\[\n\\begin{aligned}\n\\tilde{y}\\mid \\tilde{\\Bx}\\com y_{1:n}\\com \\Bx_{1:n}\n&\\sim\nt(\\nu_n\\com\\bar{y}_{n}\\com s_{n}^2)\n\\\\\n\\\\\n\\nu_{n}\n&=\n2a_n\n\\\\\n\\bar{y}_{n}\n&=\n\\tilde{\\Bx}^\\tr\\bar{\\Bbeta}_n\n\\\\\ns_{n}^2\n&=\n\\frac{b_n}{a_n}\n(1+\\tilde{\\Bx}^\\tr\\BH_n^{-1}\\tilde{\\Bx})\n.\n\\end{aligned}\n\\]\n\n\nBoth centered at point prediction;\nPoint prediction is \\(\\tilde{\\Bx}\\) times point estimate, be it OLS or posterior mean;\nBoth scaled by a factor that incorporates uncertainty from \\(\\tilde{\\varepsilon}\\) and estimation uncertainty for \\(\\Bbeta\\), be it frequentist or Bayesian;\nBoth use Student’s \\(t\\) because \\(\\sigma^2\\) also had to be estimated;\nAs \\(n\\to\\infty\\), these will actually agree thanks to the Bernstein–von Mises theorem."
  },
  {
    "objectID": "slides/case-study-2.html#you-need-to-be-thinking-about-this",
    "href": "slides/case-study-2.html#you-need-to-be-thinking-about-this",
    "title": "Case Study 2",
    "section": "You need to be thinking about this",
    "text": "You need to be thinking about this\n\nWhether you take a classical or a Bayesian approach;\nWhether you’re using the linear model or some ML behemoth;\nYou need to produce and evaluate predictive uncertainty.\n\n\nStay tuned, and we’ll show you how!"
  },
  {
    "objectID": "slides/case-study-2.html#before-lab-on-friday",
    "href": "slides/case-study-2.html#before-lab-on-friday",
    "title": "Case Study 2",
    "section": "Before lab on Friday",
    "text": "Before lab on Friday\nSkim some background reading:\n\nAruoba (2008 JMCB): “Data revisions are not well behaved;”\nCroushore (2011 JEL): “Frontiers of real-time data analysis;”\nJacobs and van Norden (2016 JoM): “Why are initial estimates of productivity growth so unreliable?”\n\nCheck out FRED and the FRBP’s Real-Time Data Set."
  },
  {
    "objectID": "slides/arma.html#time-series",
    "href": "slides/arma.html#time-series",
    "title": "Autoregressive models",
    "section": "Time series",
    "text": "Time series\n\nA time series is a set of measurements collected over time;\nWe model these data as a sequence of dependent random variables:\n\n\\[\n\\mathbf{y}_{0:T} = \\{\\mathbf{y}_0,\\,\\mathbf{y}_1,\\,\\mathbf{y}_2,\\,...,\\,\\mathbf{y}_T\\}.\n\\]\n\nA time series model is “just” their joint probability distribution:\n\n\\[\np(\\mathbf{y}_{0:T}) = p(\\mathbf{y}_0)\\prod_{t=1}^Tp(\\mathbf{y}_t\\,|\\,\\mathbf{y}_{0:t-1}).\n\\]\n\n\n\n\n\n\n\nStay grounded.\n\n\nLike much wisdom, that last bullet is simultaneously vacuous and profound. It tells you everything and it tells you nothing all at once. But don’t let this basic fact get lost in the sea of details."
  },
  {
    "objectID": "slides/arma.html#notation-to-get-used-to",
    "href": "slides/arma.html#notation-to-get-used-to",
    "title": "Autoregressive models",
    "section": "Notation to get used to",
    "text": "Notation to get used to\n\nI will not use uppercase \\(Y_t\\) versus lowercase \\(y_t\\) to distinguish random variables and fixed realizations. It’s all just \\(y_t\\), and context makes clear how it functions;\nA vector \\(\\mathbf{y}\\in\\mathbb{R}^n\\) is always an \\(n\\times 1\\) column. The corresponding row vector is \\(\\By^\\tr\\);\nFor integers \\(i&lt;j\\), you will see this shorthand all the time:\n\n\\[\ny_{i:j}\n=\n\\{y_i\\com y_{i+1}\\com y_{i+2}\\com...\\com y_{j-2}\\com y_{j-1}\\com y_{j}\\}\n.\n\\]\n\nThe symbol “\\(p\\)” will be aggressively abused and overloaded to represent any probability distribution, sometimes several in the same line:\n\n\\[\np(\\mathbf{y}_{0:T}) = p(\\mathbf{y}_0)\\prod_{t=1}^Tp(\\mathbf{y}_t\\,|\\,\\mathbf{y}_{0:t-1}).\n\\]"
  },
  {
    "objectID": "slides/arma.html#the-simplest-non-trivial-time-series-model",
    "href": "slides/arma.html#the-simplest-non-trivial-time-series-model",
    "title": "Autoregressive models",
    "section": "The simplest non-trivial time series model",
    "text": "The simplest non-trivial time series model\nThe autoregression of order 1, or AR(1):\n\n\\[\n\\begin{aligned}\ny_t\n&=\n\\beta_0\n+\n\\beta_1\ny_{t-1}\n+\n\\varepsilon_t,\n\\quad\n\\varepsilon_t\\iid\\text{N}(0\\com\\sigma^2)\n\\\\\ny_0\n&\\sim\n\\text{N}(\\mu_0\\com \\initvar),\n\\end{aligned}\n\\]\n\n\nThat’s the recursive form. It implies a joint distribution written marginal-conditional style:\n\n\n\\[\n\\begin{aligned}\np(y_{0:T})\n&=\np(y_0)\n\\prod_{t=1}^T\np(y_t\\given y_{0:t-1})\n\\\\\n&=\np(y_0)\n\\prod_{t=1}^T\np(y_t\\given y_{t-1}).\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/arma.html#the-implied-joint-distribution",
    "href": "slides/arma.html#the-implied-joint-distribution",
    "title": "Autoregressive models",
    "section": "The implied joint distribution",
    "text": "The implied joint distribution\nBecause the model is linear and Gaussian, the implied joint distribution across time is just a big ol’ multivariate normal:\n\\[\n\\begin{bmatrix}\ny_0 & y_1 & \\cdots & y_T\n\\end{bmatrix}^\\tr\n\\sim\\text{N}_{T+1}\\left(\\Bmu\\com \\BSigma\\right).\n\\]\nJust like the linear mixed model is “just” a big multivariate normal with a particular block covariance structure (dependent within and independent between groups).\n\n\n\n\n\n\n\nDon’t worry about this!\n\n\nThe mean and covariance are given by:\n\\[\n\\begin{aligned}\nE(y_t)\n&=\n\\beta_0\\sum\\limits_{i=0}^{t-1}\\beta_1^i\n+\n\\beta_1^t\\mu_0\n\\\\\n\\var(y_t)\n&=\n\\sigma^2\n\\sum\\limits_{i=0}^{t-1}\\beta_1^{2i}+\n\\beta_1^{2t}\\initvar\n\\\\\n\\cov(y_t\\com y_s)\n&=\n\\begin{cases}\n\\beta_1^{s-t}\\var(y_t) & t\\leq s\\\\\n\\beta_1^{t-s}\\var(y_s) & s &lt; t.\n\\end{cases}\n.\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/arma.html#stationarity",
    "href": "slides/arma.html#stationarity",
    "title": "Autoregressive models",
    "section": "Stationarity",
    "text": "Stationarity\nA joint distribution is (strictly) stationary if it is “shift invariant”:\n\\[\n\\{y_{t_1}\\com y_{t_2}\\com ...\\com y_{t_n}\\}\\overset{d}{=}\\{y_{t_1+h}\\com y_{t_2+h}\\com ...\\com y_{t_n+h}\\}.\n\\]\nThe Gaussian AR(1) with \\(|\\beta_1|&lt;1\\) has this property."
  },
  {
    "objectID": "slides/arma.html#stationary-ar1",
    "href": "slides/arma.html#stationary-ar1",
    "title": "Autoregressive models",
    "section": "Stationary AR(1)",
    "text": "Stationary AR(1)\nIf \\(-1&lt;\\beta_1&lt;1\\), \\(\\mu_0=\\beta_0/(1-\\beta_1)\\), and \\(\\initvar=\\sigma^2/(1-\\beta_1^2)\\), then the AR(1) is strictly stationary with the following:\n\\[\n\\begin{aligned}\nE(y_t)\n&=\n\\frac{\\beta_0}{1-\\beta_1}\n\\\\\n\\var(y_t)\n&=\n\\frac{\\sigma^2}{1-\\beta_1^2}\n\\\\\n\\cov(y_t\\com y_s)\n&=\n\\beta_1^{|t-s|}\\var(y_t)\n=\n\\beta_1^{|t-s|}\\frac{\\sigma^2}{1-\\beta_1^2}.\n\\end{aligned}\n\\]\nThe common marginal shared by all \\(y_t\\) is called the stationary distribution:\n\\[\ny_t\\sim\\text{N}\\left(\\frac{\\beta_0}{1-\\beta_1}\\com \\frac{\\sigma^2}{1-\\beta_1^2}\\right).\n\\]\nSo “did: dependent but identically distributed.”"
  },
  {
    "objectID": "slides/arma.html#autocovariance-of-a-stationary-process",
    "href": "slides/arma.html#autocovariance-of-a-stationary-process",
    "title": "Autoregressive models",
    "section": "Autocovariance of a stationary process",
    "text": "Autocovariance of a stationary process\nFor a stationary process, the covariance kernel satisfies\n\\[\n\\cov(y_t\\com y_{s})=\\cov(y_{t+h}\\com y_{s+h})\\quad \\forall (t\\com s\\com h).\n\\]\nSo you can define something called the autocovariance function:\n\\[\n\\gamma(h)=\\cov(y_{t+h}\\com y_{t}).\n\\]\nFor the AR(1), this is\n\\[\n\\begin{aligned}\n\\gamma(0)&=\\sigma^2/(1-\\beta_1^2)\n\\\\\n\\gamma(h)&=\\beta_1^h\\gamma(0).\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/arma.html#what-does-the-autocov-function-look-like",
    "href": "slides/arma.html#what-does-the-autocov-function-look-like",
    "title": "Autoregressive models",
    "section": "What does the autocov function look like?",
    "text": "What does the autocov function look like?"
  },
  {
    "objectID": "slides/arma.html#what-does-the-autocov-function-look-like-1",
    "href": "slides/arma.html#what-does-the-autocov-function-look-like-1",
    "title": "Autoregressive models",
    "section": "What does the autocov function look like?",
    "text": "What does the autocov function look like?"
  },
  {
    "objectID": "slides/arma.html#what-does-the-autocov-function-look-like-2",
    "href": "slides/arma.html#what-does-the-autocov-function-look-like-2",
    "title": "Autoregressive models",
    "section": "What does the autocov function look like?",
    "text": "What does the autocov function look like?"
  },
  {
    "objectID": "slides/arma.html#what-does-the-autocov-function-look-like-3",
    "href": "slides/arma.html#what-does-the-autocov-function-look-like-3",
    "title": "Autoregressive models",
    "section": "What does the autocov function look like?",
    "text": "What does the autocov function look like?"
  },
  {
    "objectID": "slides/arma.html#what-does-the-autocov-function-look-like-4",
    "href": "slides/arma.html#what-does-the-autocov-function-look-like-4",
    "title": "Autoregressive models",
    "section": "What does the autocov function look like?",
    "text": "What does the autocov function look like?"
  },
  {
    "objectID": "slides/arma.html#what-does-the-autocov-function-look-like-5",
    "href": "slides/arma.html#what-does-the-autocov-function-look-like-5",
    "title": "Autoregressive models",
    "section": "What does the autocov function look like?",
    "text": "What does the autocov function look like?"
  },
  {
    "objectID": "slides/arma.html#ar1-sample-paths",
    "href": "slides/arma.html#ar1-sample-paths",
    "title": "Autoregressive models",
    "section": "AR(1) sample paths",
    "text": "AR(1) sample paths\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 700\n\nlibrary(shiny)\n\nsimulate_ar_1 &lt;- function(T, b0, b1, s, m0, s0){\n  y &lt;- numeric(T)\n  y[1] &lt;- rnorm(1, m0, s0)\n  for(t in 2:T){\n    y[t] &lt;- b0 + b1 * y[t - 1] + rnorm(1, 0, s)\n  }\n  return(y)\n}\n\nar_1_mean &lt;- function(t, b0, b1, m0){\n  if(t == 0){\n    return(m0)\n  }else{\n    return(b0 * sum(b1 ^ (0:(t-1))) + m0 * (b1^t)) \n  }\n}\n\nar_1_var &lt;- function(t, b1, s, s0){\n  if(t == 0){\n    return(s0^2)\n  }else{\n    return((s0^2) * (b1^(2*t)) + (s^2) * sum(b1 ^ (2*(0:(t-1)))))\n  }\n}\n\nar_1_sd &lt;- function(t, b1, s, s0){\n  sqrt(ar_1_var(t, b1, s, s0))\n}\n\n# Define UI for application that draws a histogram\nui &lt;- fluidPage(\n  \n  # Application title\n  titlePanel(\"Marginal distributions and sample paths of a Gaussian AR(1)\"),\n  \n  # Sidebar with a slider input for number of bins \n  sidebarLayout(\n    sidebarPanel(\n      sliderInput(\"b0\",\n                  \"β₀\",\n                  min = -5,\n                  max = 5,\n                  value = 0,\n                  step = 0.1),\n      sliderInput(\"b1\",\n                  \"β₁\",\n                  min = -2,\n                  max = 2,\n                  value = 0,\n                  step = 0.1),\n      sliderInput(\"s\",\n                  \"σ\",\n                  min = 0,\n                  max = 2,\n                  value = 1, \n                  step = 0.1),\n      sliderInput(\"m0\",\n                  \"μ₀\",\n                  min = -5,\n                  max = 5,\n                  value = 0,\n                  step = 0.1),\n      sliderInput(\"T\",\n                  \"T\",\n                  min = 20,\n                  max = 200,\n                  step = 20,\n                  value = 100),\n      actionButton(\"redo\", \"New sample path\"),\n    ),\n    \n    # Show a plot of the generated distribution\n    mainPanel(\n      plotOutput(\"distPlot\", height = \"600px\")\n    )\n  )\n)\n\n# Define server logic required to draw a histogram\nserver &lt;- function(input, output) {\n  \n  output$distPlot &lt;- renderPlot({\n    input$redo\n    b0 &lt;- input$b0\n    b1 &lt;- input$b1\n    redo &lt;- input$redo\n    T &lt;- input$T\n    s &lt;- input$s\n    m0 &lt;- input$m0\n    s0 = 1\n    \n    range = 0:T\n    alpha = c(0.01, seq(0.1, 0.9, by = 0.1))\n    \n    middle &lt;- sapply(range, ar_1_mean, b0, b1, m0)\n    sds &lt;- sapply(range, ar_1_sd, b1, s, s0)\n    \n    \n    plot(range, middle, type = \"l\",\n         xaxt = \"n\", \n         yaxt = \"n\",\n         xlab = \"t\",\n         ylab = expression(y[t]),\n         ylim = c(-20, 20), bty = \"n\",\n         col = \"white\")\n    \n    for(a in alpha){\n      \n      U = qnorm(1 - a / 2, mean = middle, sd = sds)\n      L = qnorm(a / 2, mean = middle, sd = sds)\n      \n      polygon(\n        c(range, rev(range)),\n        c(U, rev(L)),\n        col = rgb(1, 0, 0, 0.15),\n        border = NA\n      )\n    }\n    \n    inc = 20\n    axis(1, pos = 0, at = seq(0, max(range), by = inc), \n         labels = c(NA, seq(inc, max(range), by = inc)))\n    axis(2, pos = 0)\n    \n    lines(range, simulate_ar_1(max(range) + 1, b0, b1, s, m0, s0), col = \"black\", lwd = 2)\n  })\n}\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "slides/arma.html#arp",
    "href": "slides/arma.html#arp",
    "title": "Autoregressive models",
    "section": "AR(p)",
    "text": "AR(p)\nThe autoregression of order \\(p\\), or AR(\\(p\\)):\n\n\\[\n\\begin{aligned}\ny_t\n&=\n\\beta_0\n+\n\\beta_1\ny_{t-1}\n+\n\\beta_2\ny_{t-2}\n+\n\\cdots\n+\n\\beta_p\ny_{t-p}\n+\n\\varepsilon_t,\n\\quad\n\\varepsilon_t\\iid\\text{N}(0\\com\\sigma^2)\n\\\\\n\\begin{bmatrix}\ny_0\n\\\\\ny_{-1}\n\\\\\n\\vdots\n\\\\\ny_{1-p}\n\\end{bmatrix}\n&\\sim\n\\text{N}_p(\\Bmu_0\\com \\BP_0).\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/arma.html#lets-improve-the-notation",
    "href": "slides/arma.html#lets-improve-the-notation",
    "title": "Autoregressive models",
    "section": "Let’s improve the notation",
    "text": "Let’s improve the notation\nThe autoregression of order p, or AR(p):\n\n\\[\n\\begin{aligned}\ny_t\n&=\n\\beta_0\n+\n\\sum\\limits_{\\ell=1}^p\n\\beta_\\ell\ny_{t-\\ell}\n+\n\\varepsilon_t,\n\\quad\n\\varepsilon_t\\iid\\text{N}(0\\com\\sigma^2).\n\\end{aligned}\n\\]\n\n\nThis implies a joint distribution governed by a finite set of static parameters \\(\\Btheta = \\begin{bmatrix}\\beta_0&\\beta_1&\\cdots &\\beta_p&\\sigma^2\\end{bmatrix}^\\tr\\):\n\n\n\\[\n\\begin{aligned}\np(y_{1:T}\\given y_{1-p:0}\\com\\Btheta)\n&=\n\\prod_{t=1}^T\np(y_t\\given y_{t-p:t-1}\\com\\Btheta).\n\\end{aligned}\n\\]\n\n\nViewed as a function of \\(\\Btheta\\), that’s a (conditional) likelihood!\n\n\nMaximize it, or combine with a prior."
  },
  {
    "objectID": "slides/arma.html#maximum-likelihood-estimation-1",
    "href": "slides/arma.html#maximum-likelihood-estimation-1",
    "title": "Autoregressive models",
    "section": "Maximum likelihood estimation",
    "text": "Maximum likelihood estimation\nTreating the observed data \\(y_{1-p:T}\\) as fixed, we want:\n\\[\n\\hat{\\Btheta}_T=\\argmax{\\Btheta}\\,p(y_{1:T}\\given y_{1-p:0}\\com \\Btheta).\n\\]\nTo do this, it helps to view the AR(p) is “just” a multiple linear regression where \\(\\Bx_t\\) encodes the lagged values of \\(y_t\\):\n\\[\n\\begin{aligned}\ny_t&=\\Bx_t^\\tr\\Bbeta+\\varepsilon_t,&&\\varepsilon_t\\iid\\N(0\\com\\sigma^2)\n\\\\\n\\Bx_t&=\\begin{bmatrix}\n1 & y_{t-1} & y_{t-2} & \\cdots & y_{t-p}\n\\end{bmatrix}^\\tr\\\\\n\\Bbeta&=\\begin{bmatrix}\n\\beta_0 & \\beta_1 & \\beta_2 & \\cdots & \\beta_p\n\\end{bmatrix}^\\tr.\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/arma.html#maximum-likelihood-estimation-2",
    "href": "slides/arma.html#maximum-likelihood-estimation-2",
    "title": "Autoregressive models",
    "section": "Maximum likelihood estimation",
    "text": "Maximum likelihood estimation\nSince \\(y_t\\given \\Bx_t\\com\\Btheta\\sim\\N\\left(\\Bx_t^\\tr\\Bbeta\\com\\sigma^2\\right)\\), we have\n\n\\[\n\\begin{aligned}\np(y_{1:T}\\given  \\Bx_0\\com \\Btheta)\n&=\n\\prod_{t=1}^T\np(y_t\\given \\Bx_t\\com\\Btheta)\n\\\\\n&=\n\\prod_{t=1}^T\n\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{1}{2}\\frac{(y_t-\\Bx_t^\\tr\\Bbeta)^2}{\\sigma^2}\\right)\n\\\\\n&=\n(2\\pi\\sigma^2)^{-T/2}\n\\exp\\left(-\\frac{1}{2\\sigma^2}\\sum\\limits_{t=1}^T(y_t-\\Bx_t^\\tr\\Bbeta)^2\\right)\n.\n\\end{aligned}\n\\]\n\n\nTo compute the MLE, we treat this as a function of \\(\\Btheta\\) with the data fixed."
  },
  {
    "objectID": "slides/arma.html#stack-em-up",
    "href": "slides/arma.html#stack-em-up",
    "title": "Autoregressive models",
    "section": "Stack ’em up",
    "text": "Stack ’em up\nConstruct the response vector and design matrix:\n\n\\[\n\\begin{aligned}\n\\underbrace{\\By_T}_{T\\times 1}\n&=\n\\begin{bmatrix}y_1&y_2 & \\cdots & y_T\\end{bmatrix}^\\tr\n\\\\\n\\underbrace{\\BX_T}_{T\\times (p+1)}\n&=\n\\begin{bmatrix}\n1 & y_0 & y_{-1} & \\cdots & y_{1-p} \\\\\n1 & y_1 & y_0 & \\cdots & y_{2-p} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & y_{T-1} & y_{T-2} & \\cdots & y_{T-p}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\Bx_1^\\tr\\\\\n\\Bx_2^\\tr\\\\\n\\vdots\\\\\n\\Bx_T^\\tr\n\\end{bmatrix}\n.\n\\end{aligned}\n\\]\n\n\nSo the likelihood is:\n\\[\n\\begin{aligned}\np(y_{1:T}\\given  \\Bx_0\\com \\Btheta)\n&=\n(2\\pi\\sigma^2)^{-T/2}\n\\exp\\left(-\\frac{1}{2\\sigma^2}\\sum\\limits_{t=1}^T(y_t-\\Bx_t^\\tr\\Bbeta)^2\\right)\n\\\\\n&=\n(2\\pi\\sigma^2)^{-T/2}\n\\exp\\left(-\\frac{1}{2\\sigma^2}||\\By_T-\\BX_T\\Bbeta||_2^2\\right)\n.\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/arma.html#what-are-we-doing",
    "href": "slides/arma.html#what-are-we-doing",
    "title": "Autoregressive models",
    "section": "What are we doing?",
    "text": "What are we doing?\nLikelihood:\n\\[\n\\begin{aligned}\nL(\\Bbeta\\com\\sigma^2)\n&=\n(2\\pi\\sigma^2)^{-T/2}\n\\exp\\left(-\\frac{1}{2\\sigma^2}||\\By_T-\\BX_T\\Bbeta||_2^2\\right)\n.\n\\end{aligned}\n\\]\nLog-likelihood:\n\\[\n\\ell(\\Bbeta\\com\\sigma^2)\n=\n-\\frac{T}{2}\\ln(2\\pi\\sigma^2)\n-\\frac{1}{2\\sigma^2}\n||\\By_T-\\BX_T\\Bbeta||_2^2\n,\n\\]\nWe want:\n\\[\n\\begin{aligned}\n\\hat{\\Bbeta}_T\\com \\hat{\\sigma_T^2}\n&=\\argmax{\\Bbeta\\com\\sigma^2}\\,\\ell(\\Bbeta\\com\\sigma^2).\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/arma.html#ols-for-the-arp",
    "href": "slides/arma.html#ols-for-the-arp",
    "title": "Autoregressive models",
    "section": "OLS for the AR(p)",
    "text": "OLS for the AR(p)\n\n\nThe maximum (conditional) likelihood estimator in the AR(p) is the same as the ordinary least squares estimator:\n\n\n\n\\[\n\\begin{aligned}\n\\hat{\\Bbeta}_T\n&=\n(\\BX_T^\\tr\\BX_T)^{-1}\\BX_T^\\tr\\By_T\n\\\\\n\\hat{\\sigma^2_T}\n&=\n||\\By_T-\\BX_T\\hat{\\Bbeta}_T||_2^2 / T.\n\\end{aligned}\n\\]\n\n\n\nIt doesn’t matter that there’s time series dependence. Once the data are observed and fixed, the mechanics are identical to iid multiple regression;\nFor things like prediction, dependence matters, and the correspondence with iid regression breaks down."
  },
  {
    "objectID": "slides/arma.html#bayes-is-just-like-iid-regression-too",
    "href": "slides/arma.html#bayes-is-just-like-iid-regression-too",
    "title": "Autoregressive models",
    "section": "Bayes is just like iid regression too",
    "text": "Bayes is just like iid regression too\nBayesian model with a conjugate prior:\n\\[\n\\begin{aligned}\n\\sigma^2\n&\\sim\n\\text{IG}(a_0\\com b_0)\n\\\\\n\\Bbeta\\given \\sigma^2\n&\\sim\n\\text{N}_{p+1}(\\Bm_0\\com\\sigma^2\\BH^{-1}_0)\n\\\\\ny_t\n\\given\n\\Bx_t\n\\com\n\\Bbeta\\com\\sigma^2\n&\\sim \\text{N}\n\\left(\n\\Bx_t^\\tr\\Bbeta\\com\\sigma^2\n\\right).\n\\end{aligned}\n\\]\n\nThe posterior is available in closed-form:\n\\[\n\\begin{aligned}\n\\sigma^2\\given y_{0:T}\n&\\sim\n\\text{IG}(a_T\\com b_T)\n\\\\\n\\Bbeta\\given \\sigma^2\\com y_{0:T}\n&\\sim\n\\text{N}_{p+2}(\\Bm_T\\com\\sigma^2\\BH^{-1}_T)\n\\\\\n\\\\\n\\BH_T\n&=\n\\BX_T^\\tr\\BX_T+\\BH_0\n\\\\\n\\Bm_T\n&=\n\\BH_T^{-1}(\\BX_T^\\tr\\By_T+\\BH_0\\Bm_0)\n\\\\\na_T\n&=\na_0 + T/2\n\\\\\nb_T\n&=\nb_0\n+\n(\\By_T^\\tr\\By_T+\\Bm_0^\\tr\\BH_0\\Bm_0-\\Bm_T^\\tr\\BH_T\\Bm_T)/2.\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/arma.html#one-step-posterior-predictive-distribution",
    "href": "slides/arma.html#one-step-posterior-predictive-distribution",
    "title": "Autoregressive models",
    "section": "One-step posterior predictive distribution",
    "text": "One-step posterior predictive distribution\nWe want\n\n\\[\np(y_{t+1}\\given y_{0:t})\n=\n\\int\n\\int\np(y_{t+1}\\given\\Bbeta\\com\\sigma^2\\com y_{0:t})p(\\Bbeta\\com\\sigma^2\\given y_{0:t})\\,\\dd\\Bbeta\\,\\dd\\sigma^2\n,\n\\]\n\n\nand we know that\n\\[\n\\begin{aligned}\n\\sigma^2\\given y_{0:t}\n&\\sim\n\\text{IG}(a_t\\com b_t)\n\\\\\n\\Bbeta\\given \\sigma^2\\com y_{0:t}\n&\\sim\n\\text{N}_{p+1}(\\Bm_t\\com\\sigma^2\\BH^{-1}_t)\n\\\\\ny_{t+1}\\given\\Bbeta\\com \\sigma^2\\com y_{0:t}\n&\\sim \\N(\\Bx_{t+1}^\\tr\\Bbeta\\com\\sigma^2).\n\\end{aligned}\n\\]\n\n\nThere is actually a closed-form solution."
  },
  {
    "objectID": "slides/arma.html#marginalize-out-bbeta",
    "href": "slides/arma.html#marginalize-out-bbeta",
    "title": "Autoregressive models",
    "section": "Marginalize out \\(\\Bbeta\\)\n",
    "text": "Marginalize out \\(\\Bbeta\\)\n\nWe know that\n\\[\n\\begin{aligned}\n\\Bbeta\\given \\sigma^2\\com y_{0:t}\n&\\sim\n\\text{N}_{p+1}(\\Bm_t\\com\\sigma^2\\BH^{-1}_t)\n\\\\\ny_{t+1}\n&=\n\\Bx_{t+1}^\\tr\\Bbeta\n+\n\\varepsilon_{t+1}\n,\n&&\n\\varepsilon_{t+1}\\sim\\N(0\\com \\sigma^2).\n\\end{aligned}\n\\]\n\nBy affine transformation:\n\\[\n\\Bx_{t+1}^\\tr\\Bbeta\n\\given \\sigma^2\\com y_{0:t}\n\\sim\n\\N(\n\\Bx_{t+1}^\\tr\\Bm_t\n\\com\n\\sigma^2\\Bx_{t+1}^\\tr\\BH_t^{-1}\\Bx_{t+1}\n).\n\\]\n\n\nBy linear combination of independent normals:\n\\[\n\\begin{aligned}\ny_{t+1}\\given \\sigma^2\\com y_{0:t}\n&\\sim \\N\\left(\\Bx_{t+1}^\\tr\\Bm_t\\com\\sigma^2(1+\\Bx_{t+1}^\\tr\\BH_t^{-1}\\Bx_{t+1})\\right).\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/arma.html#marginalize-out-sigma2",
    "href": "slides/arma.html#marginalize-out-sigma2",
    "title": "Autoregressive models",
    "section": "Marginalize out \\(\\sigma^2\\)\n",
    "text": "Marginalize out \\(\\sigma^2\\)\n\nWe know that\n\\[\n\\begin{aligned}\n\\sigma^2\\given y_{0:t}\n&\\sim\n\\text{IG}(a_t\\com b_t)\n\\\\\ny_{t+1}\\given \\sigma^2\\com y_{0:t}\n&\\sim \\N\\left(\\Bx_{t+1}^\\tr\\Bm_t\\com\\sigma^2(1+\\Bx_{t+1}^\\tr\\BH_t^{-1}\\Bx_{t+1})\\right).\n\\end{aligned}\n\\]\n\nMarginalizing \\(\\sigma^2\\) out of this hierarchy is essentially the definition of Student’s \\(t\\):\n\n\n\\[\n\\begin{aligned}\ny_{t+1}\\given y_{0:t}\n&\\sim\nt(\\nu_{t+1|t}\\com\\bar{y}_{t+1|t}\\com s_{t+1|t}^2)\n\\\\\n\\\\\n\\nu_{t+1|t}\n&=\n2a_t\n\\\\\n\\bar{y}_{t+1|t}\n&=\n\\Bx_{t+1}^\\tr\\Bm_t\n\\\\\ns_{t+1|t}^2\n&=\n\\frac{b_t}{a_t}\n(1+\\Bx_{t+1}^\\tr\\BH_t^{-1}\\Bx_{t+1})\n.\n\\end{aligned}\n\\]\n\n\nSo, Student’s \\(t\\) with location-scale."
  },
  {
    "objectID": "syllabus/syllabus-assignments.html",
    "href": "syllabus/syllabus-assignments.html",
    "title": "Assignments and grading",
    "section": "",
    "text": "Course grade\nYour final course grade breaks down as follows:\n\n[10%] Attendance and participation: we will be taking attendance at all class meetings;\n[15%] Final project: the semester ends with a data analysis project completed individually. Details to come;\n[75%] Case studies: this course is organized around a sequence of case studies where you work in teams to analyze complex, messy datasets coming from various domains. There will be 4 - 6 case studies depending on the pace of course, and they will each get equal weight in determining this course component. Within each case study, your grade breaks down as follows:\n\n(60%) written report;\n(30%) presentation;\n(10%) student-specific collaboration score.\n\n\nAt the end of the semester, your final letter grade will be determined using the usual thresholds:\n\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n&lt; 60\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThese thresholds will not be adjusted upward, but they may be adjusted downward in your favor.\n\n\n\n\nCase studies\nThe case studies are the heart of the class. Case studies will last 2 - 4 weeks depending on complexity, and there will be 4 - 6 in total. Sometimes the class as a whole requests more time to work on the more involved cases, and so we are prepared to be flexible and adjust the pace of the course as needed. Hence, the final number of cases is TBD.\nEach case study will go something like this:\n\nthe instructor introduces the data and the research question in lecture;\nstudents are randomly sorted into teams of 2 - 4. The teams are different for every case study;\njust like in STA 199, we share a GitHub repo with each team that contains the necessary data as well as template Quarto files for your presentation and report;\nworking inside their GitHub repo, teams use R and Quarto to collaborate on a written report and presentation slides;\nduring lecture, the instructor introduces new statistical topic that teams may find relevant to the current case study;\nEach case study has two rounds of presentation: an early stage presentation on exploratory work and a final presentation on analysis. Groups will be selected at random to present in one of these two rounds, with each group presenting at least once for each case study;\nLab sections on Friday will sometimes feature a presentation or tutorial, but for the most part these are built-in work periods where all group members can convene with access to a TA;\nAt the end of each case study, students will confidentially evaluate themselves and their group members with a survey through TEAMMATES. Only the teaching team will have access to this feedback.\n\nAs mentioned above, each case study will be graded as follows:\n\n(60%) at the end you submit a brief report describing your final analysis;\n\nsee here for the grading rubric;\n\n(30%) you will give at least one presentation, on your exploratory or final analysis;\n\nsee here for the grading rubric;\n\n(10%) based on your GitHub activity and the results of the TEAMMATES survey, each individual group member will receive a separate score reflecting their contribution to the team’s effort."
  },
  {
    "objectID": "syllabus/syllabus-policies.html#attendance",
    "href": "syllabus/syllabus-policies.html#attendance",
    "title": "Policies",
    "section": "Attendance",
    "text": "Attendance"
  },
  {
    "objectID": "syllabus/syllabus-policies.html#use-of-ai",
    "href": "syllabus/syllabus-policies.html#use-of-ai",
    "title": "Policies",
    "section": "Use of AI",
    "text": "Use of AI"
  },
  {
    "objectID": "syllabus/syllabus-policies.html#academic-honesty",
    "href": "syllabus/syllabus-policies.html#academic-honesty",
    "title": "Policies",
    "section": "Academic honesty",
    "text": "Academic honesty"
  }
]